"""

Main executable for the document structure parser. 

Usage:

   % python main.py TEXT_FILE FACT_FILE STRUCTURE_FILE COLLECTION?
   % python main.py FILE_LIST COLLECTION?
   % python main.py DIRECTORY COLLECTION?

In the first form, input is taken from TEXT_FILE, which contains the bare text, and
FACT_FILE, which contains some structural tags taken from the low-level input parser. The
output is written to STRUCTURE_FILE, which has lines like the following

   SECTION ID=1 TYPE="UNLABELED" START=0 END=3978
   SECTION ID=2 TYPE="INTRODUCTION" TITLE="INTRODUCTION" START=3978 END=6016

In the second form, the input and output files are specified in the file FILE_LIST. In the
third form, all pairs of .txt and .fact files in DIRECTORY are processed and .sect files
are created.

The optional COLLECTION argument specifies the collection that the input document was
taken from. This can be used to overrule the default behaviour, which is to scan the fact
file and find the following line:

   DOCUMENT COLLECTION="$COLLECTION"

In this line, $COLLECTION is in ('WEB_OF_SCIENCE', 'LEXISNEXIS', 'PUBMED', 'ELSEVIER').

"""


import os, sys, codecs, re
import sections, elsevier1


def process_file(text_file, fact_file, sect_file, collection):
    """
    Takes a text file and a fact file and creates a .sections file with the section data.
    The data in fact_file can have two formats: (i) the format generated by the BAE
    wrapper and (ii) the format generated by create_standoff.pl. """
    section_factory = create_factory(text_file, fact_file, sect_file, collection)
    try:
        section_factory.make_sections()
        f = codecs.open(section_factory.sect_file, "w", encoding='utf-8')
        section_factory.print_sections(f)
        f.close()
    except UserWarning:
        print 'WARNING:', sys.exc_value

def process_files(file_list, collection):
    """
    Takes a file with names of input and output files and processes them. Each line in the
    file has three filenames, separated by tabs, the first file is the text inut file, the
    second the fact input file, and the third the output file."""
    for line in open(file_list):
        (txt_file, fact_file, sections_file) = line.strip().split()
        process_file(txt_file, fact_file, sections_file, collection)

def process_directory(path, collection):
    """
    Processes all files in a directory with text and fact files. Takes all .txt files,
    finds sister files with extension .fact and then creates .sect files."""
    text_files = []
    fact_files= {}
    for f in os.listdir(path):
        if f.endswith('.txt'): text_files.append(f)
        if f.endswith('.fact'): fact_files[f] = True
    for text_file in text_files:
        fact_file = text_file[:-4] + '.fact'
        sect_file = text_file[:-4] + '.sect'
        if fact_files.has_key(fact_file):
            text_file = os.path.join(path, text_file)
            fact_file = os.path.join(path, fact_file)
            sect_file = os.path.join(path, sect_file)
            process_file(text_file, fact_file, sect_file, collection)

def create_factory(text_file, fact_file, sect_file, collection):
    """
    Returns the factory needed given the collection parameter and specifications in the
    fact file and, if needed, some characteristics gathered from the text file."""
    if collection is None:
        collection = determine_collection(fact_file)
    if collection == 'PUBMED': 
        return sections.BiomedNxmlSectionFactory(text_file, fact_file, sect_file)        
    elif collection == 'WEB_OF_SCIENCE':
        return sections.WebOfScienceSectionFactory(text_file, fact_file, sect_file)        
    elif collection == 'LEXISNEXIS':
        return sections.PatentSectionFactory(text_file, fact_file, sect_file)        
    elif collection == 'ELSEVIER':
        return create_elsevier_factory(text_file, fact_file, sect_file)

def  create_elsevier_factory(text_file, fact_file, sect_file):
    """
    Since Elsevier data come in two flavours and each flavour has its own factory, check
    the file to make sure what kind of Elsevier document we are dealing with. It appears
    that counting occurrences of the TEXT type in the fact file predicts whether an
    Elsevier file is structured or not with a precision of about 0.99."""
    fh = open(fact_file)
    text_tags = len( [l for l in fh.readlines() if l.find('TEXT') > -1] )
    fh.close()
    if text_tags < 4 :
        return elsevier1.SimpleElsevierSectionFactory(text_file, fact_file, sect_file)
    else:
        return sections.ComplexElsevierSectionFactory(text_file, fact_file, sect_file)

def determine_collection(fact_file):
    """
    Loop through the fact file in order to find the line that specifies the collection."""
    # THIS CODE HAS NOT YET BEEN PROPERLY TESTED
    expr = re.compile('DOCUMENT.*COLLECTION="(\S+)"')
    for line in open(fact_file):
        result = expr.search(line)
        if result is not None:
            return result.group(1)
    return None

    
if __name__ == '__main__':

    #collection = None

    # when called to process one file
    if len(sys.argv) > 3:
        text_file, fact_file, sect_file = sys.argv[1:4]
        collection = sys.argv[4] if len(sys.argv) > 4 else None
        process_file(text_file, fact_file, sect_file, collection)

    # processing multiple files
    else:
        path = sys.argv[1]
        collection = sys.argv[2] if len(sys.argv) > 2 else None
        # using directory
        if os.path.isdir(path):
            process_directory(path, collection)
        # using a file that lists files to process
        elif os.path.isfile(path):
            process_files(path, collection)
